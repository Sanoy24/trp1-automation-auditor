"""
justice.py — The Supreme Court / Chief Justice Synthesis Engine.

The ChiefJusticeNode does NOT merely average scores.  It applies
deterministic, hardcoded Python rules to resolve the dialectical
conflict generated by the three Judges.  LLM is used ONLY for
narrative generation (executive summary, remediation text) — never
for score calculation.

Constitutional Rules (from rubric synthesis_rules):
  1. Rule of Security    — security flaw caps score at 3
  2. Rule of Evidence    — fact supremacy overrules Defence hallucination
  3. Rule of Functionality — TechLead carries highest weight for architecture
  4. Dissent Requirement — variance > 2 mandates dissent summary
  5. Variance Re-evaluation — variance > 2 re-weights towards median
"""

from __future__ import annotations

import json
import logging
from statistics import median
from typing import Any, Dict, List, Optional

from langchain_core.messages import HumanMessage, SystemMessage

from src.llm import get_llm
from src.state import (
    AgentState,
    AuditReport,
    CriterionResult,
    Evidence,
    JudicialOpinion,
)

logger = logging.getLogger(__name__)

# ---------------------------------------------------------------------------
# Security-related evidence keywords (for Rule of Security)
# ---------------------------------------------------------------------------

SECURITY_VIOLATION_MARKERS = [
    "os.system",
    "shell injection",
    "SECURITY VIOLATION",
    "Security Negligence",
    "unsanitized",
]

# Architecture criterion IDs where TechLead carries highest weight
ARCHITECTURE_CRITERIA = {"graph_orchestration", "state_management_rigor"}


# ---------------------------------------------------------------------------
# Deterministic conflict resolution
# ---------------------------------------------------------------------------


def _has_security_violation(evidences: Dict[str, List[Evidence]]) -> bool:
    """Check if any detective evidence confirms a security violation."""
    for source, evidence_list in evidences.items():
        for ev in evidence_list:
            if ev.content:
                for marker in SECURITY_VIOLATION_MARKERS:
                    if marker.lower() in ev.content.lower():
                        return True
            if ev.rationale:
                for marker in SECURITY_VIOLATION_MARKERS:
                    if marker.lower() in ev.rationale.lower():
                        return True
    return False


def _evidence_supports_claim(
    evidences: Dict[str, List[Evidence]],
    criterion_id: str,
) -> bool:
    """Check if detective evidence actually supports the claims for a criterion.

    Returns True if at least one evidence item for this criterion area
    has found=True.  Returns False if evidence is missing or contradicts.
    """
    # Map criterion IDs to evidence goals/locations they relate to
    for source, evidence_list in evidences.items():
        for ev in evidence_list:
            if ev.found and (
                criterion_id.replace("_", " ") in ev.goal.lower()
                or criterion_id.replace("_", " ") in ev.location.lower()
            ):
                return True
    return False


def _resolve_criterion(
    criterion_id: str,
    criterion_name: str,
    opinions: List[JudicialOpinion],
    evidences: Dict[str, List[Evidence]],
    synthesis_rules: Dict[str, str],
) -> CriterionResult:
    """Apply deterministic constitutional rules to resolve a single criterion.

    This is pure Python logic — no LLM involved in score determination.
    """
    if not opinions:
        return CriterionResult(
            dimension_id=criterion_id,
            dimension_name=criterion_name,
            final_score=1,
            judge_opinions=[],
            dissent_summary="No judicial opinions received for this criterion.",
            remediation="Unable to assess — no judge opinions available.",
        )

    # Extract opinions by judge role
    prosecutor_opinions = [o for o in opinions if o.judge == "Prosecutor"]
    defense_opinions = [o for o in opinions if o.judge == "Defense"]
    tech_lead_opinions = [o for o in opinions if o.judge == "TechLead"]

    scores = [o.score for o in opinions]
    score_variance = max(scores) - min(scores) if scores else 0

    # --- Rule of Functionality (weight distribution) ---
    # TechLead carries highest weight for architecture criteria
    if criterion_id in ARCHITECTURE_CRITERIA and tech_lead_opinions:
        # Weighted: TechLead=0.5, Prosecutor=0.25, Defense=0.25
        tech_score = tech_lead_opinions[0].score
        pros_score = prosecutor_opinions[0].score if prosecutor_opinions else tech_score
        def_score = defense_opinions[0].score if defense_opinions else tech_score
        weighted = (tech_score * 0.5) + (pros_score * 0.25) + (def_score * 0.25)
    else:
        # Default equal weighting
        weighted = sum(scores) / len(scores) if scores else 3.0

    # --- Rule 5: Variance Re-evaluation ---
    # If variance > 2, re-weight towards the median judge
    if score_variance > 2:
        median_score = median(scores)
        # Blend weighted score towards median (60% median, 40% original weighted)
        weighted = (median_score * 0.6) + (weighted * 0.4)
        logger.info(
            "Criterion '%s': variance=%d > 2, re-weighted towards median=%d → %.1f",
            criterion_id,
            score_variance,
            median_score,
            weighted,
        )

    # Round to nearest int, clamp 1-5
    final_score = max(1, min(5, round(weighted)))

    # --- Rule of Security ---
    # Confirmed security flaw caps score at 3
    security_violated = _has_security_violation(evidences)
    if security_violated and criterion_id in {
        "safe_tool_engineering",
        "graph_orchestration",
        "structured_output_enforcement",
    }:
        if final_score > 3:
            logger.warning(
                "RULE OF SECURITY: Capping '%s' score from %d to 3 due to security violation.",
                criterion_id,
                final_score,
            )
            final_score = 3

    # --- Rule of Evidence (Fact Supremacy) ---
    # If Defense claims high score but detective evidence shows artifact missing,
    # Defense is overruled
    if defense_opinions and defense_opinions[0].score >= 4:
        if not _evidence_supports_claim(evidences, criterion_id):
            old_score = final_score
            # Reduce score — facts overrule opinions
            final_score = min(final_score, 2)
            logger.warning(
                "RULE OF EVIDENCE: Defense claimed score %d for '%s' "
                "but detective evidence does not support. "
                "Reducing from %d to %d.",
                defense_opinions[0].score,
                criterion_id,
                old_score,
                final_score,
            )

    # --- Rule 4: Dissent Requirement ---
    dissent_summary = None
    if score_variance > 2:
        # Build dissent narrative from the opposing arguments
        parts = []
        if prosecutor_opinions:
            parts.append(
                f"Prosecutor (score {prosecutor_opinions[0].score}): "
                f"{prosecutor_opinions[0].argument[:200]}"
            )
        if defense_opinions:
            parts.append(
                f"Defense (score {defense_opinions[0].score}): "
                f"{defense_opinions[0].argument[:200]}"
            )
        if tech_lead_opinions:
            parts.append(
                f"TechLead (score {tech_lead_opinions[0].score}): "
                f"{tech_lead_opinions[0].argument[:200]}"
            )
        dissent_summary = (
            f"Score variance of {score_variance} exceeded threshold of 2. "
            + " | ".join(parts)
        )

    # Build remediation text from the opinions
    remediation_parts = []
    for opinion in opinions:
        if opinion.score <= 3:
            remediation_parts.append(
                f"[{opinion.judge}] {opinion.argument[:150]}"
            )
    remediation = (
        " || ".join(remediation_parts)
        if remediation_parts
        else "No specific remediation needed — criterion scored well across all judges."
    )

    return CriterionResult(
        dimension_id=criterion_id,
        dimension_name=criterion_name,
        final_score=final_score,
        judge_opinions=opinions,
        dissent_summary=dissent_summary,
        remediation=remediation,
    )


# ---------------------------------------------------------------------------
# LLM-assisted narrative generation (NOT for scoring)
# ---------------------------------------------------------------------------


def _generate_executive_summary(
    criteria: List[CriterionResult],
    repo_url: str,
) -> str:
    """Use LLM to generate an executive summary from the resolved criteria."""
    try:
        llm = get_llm(role="justice", temperature=0.3)

        criteria_summary = "\n".join(
            f"- {c.dimension_name}: {c.final_score}/5"
            + (f" [DISSENT: {c.dissent_summary[:100]}]" if c.dissent_summary else "")
            for c in criteria
        )

        prompt = (
            f"You are writing an Executive Summary for an audit report of the "
            f"repository: {repo_url}.\n\n"
            f"The audit assessed the repository across the following criteria:\n"
            f"{criteria_summary}\n\n"
            f"Write a concise executive summary (3-5 sentences) that:\n"
            f"1. States the overall quality level\n"
            f"2. Highlights the strongest areas\n"
            f"3. Identifies the most critical gaps\n"
            f"4. Gives a high-level recommendation\n\n"
            f"Be professional and specific. Do not use generic platitudes."
        )

        response = llm.invoke([HumanMessage(content=prompt)])
        return response.content
    except Exception as exc:
        logger.warning("Executive summary LLM generation failed: %s", exc)
        overall = sum(c.final_score for c in criteria) / len(criteria) if criteria else 0
        return (
            f"Automated audit of {repo_url} completed. "
            f"Overall score: {overall:.1f}/5 across {len(criteria)} criteria."
        )


def _generate_remediation_plan(
    criteria: List[CriterionResult],
) -> str:
    """Use LLM to generate a consolidated remediation plan."""
    try:
        llm = get_llm(role="justice", temperature=0.3)

        failing_criteria = [c for c in criteria if c.final_score <= 3]
        if not failing_criteria:
            return "No critical remediation needed — all criteria scored above 3."

        details = "\n".join(
            f"- [{c.dimension_name} ({c.final_score}/5)]: {c.remediation[:200]}"
            for c in failing_criteria
        )

        prompt = (
            f"Based on the following audit findings, write a specific, "
            f"file-level remediation plan. Group recommendations by priority.\n\n"
            f"Failing Criteria:\n{details}\n\n"
            f"For each item, specify:\n"
            f"1. Which file(s) to modify\n"
            f"2. What specific change to make\n"
            f"3. Why this change is important\n\n"
            f"Be actionable and specific."
        )

        response = llm.invoke([HumanMessage(content=prompt)])
        return response.content
    except Exception as exc:
        logger.warning("Remediation plan LLM generation failed: %s", exc)
        parts = []
        for c in criteria:
            if c.final_score <= 3:
                parts.append(f"- {c.dimension_name} ({c.final_score}/5): {c.remediation}")
        return "\n".join(parts) if parts else "No remediation items identified."


# ---------------------------------------------------------------------------
# LangGraph Node: ChiefJusticeNode
# ---------------------------------------------------------------------------


def chief_justice_node(state: AgentState) -> Dict[str, Any]:
    """LangGraph node: The Chief Justice — Synthesis Engine.

    Applies deterministic constitutional rules to resolve the dialectical
    conflict from the three Judges, then generates the final AuditReport.

    Constitutional Rules applied:
      1. Rule of Security     — caps score at 3 for security violations
      2. Rule of Evidence     — overrules Defence when facts contradict
      3. Rule of Functionality — TechLead weight highest for architecture
      4. Dissent Requirement  — variance > 2 mandates dissent summary
      5. Variance Re-evaluation — re-weights towards median on high variance
    """
    logger.info("=== CHIEF JUSTICE entering deliberation ===")

    repo_url = state.get("repo_url", "unknown")
    opinions = state.get("opinions", [])
    evidences = state.get("evidences", {})
    rubric_dimensions = state.get("rubric_dimensions", [])

    # Load synthesis rules from rubric — these complement the hardcoded rules
    synthesis_rules = {}
    for dim in rubric_dimensions:
        sr = dim.get("synthesis_rules")
        if sr:
            synthesis_rules[dim["id"]] = sr

    # Build a lookup: criterion_id → dimension metadata
    dim_lookup = {d["id"]: d for d in rubric_dimensions}

    # Group opinions by criterion_id
    opinions_by_criterion: Dict[str, List[JudicialOpinion]] = {}
    for opinion in opinions:
        cid = opinion.criterion_id
        if cid not in opinions_by_criterion:
            opinions_by_criterion[cid] = []
        opinions_by_criterion[cid].append(opinion)

    # Resolve each criterion using deterministic rules
    criteria_results: List[CriterionResult] = []
    for dim in rubric_dimensions:
        cid = dim["id"]
        cname = dim.get("name", cid)
        dim_opinions = opinions_by_criterion.get(cid, [])

        result = _resolve_criterion(
            criterion_id=cid,
            criterion_name=cname,
            opinions=dim_opinions,
            evidences=evidences,
            synthesis_rules=synthesis_rules,
        )
        criteria_results.append(result)
        logger.info(
            "Criterion '%s' resolved: final_score=%d (from %d opinions)",
            cid,
            result.final_score,
            len(dim_opinions),
        )

    # Calculate overall score
    overall_score = (
        sum(c.final_score for c in criteria_results) / len(criteria_results)
        if criteria_results
        else 1.0
    )
    overall_score = round(max(1.0, min(5.0, overall_score)), 1)

    # Generate narrative sections via LLM
    executive_summary = _generate_executive_summary(criteria_results, repo_url)
    remediation_plan = _generate_remediation_plan(criteria_results)

    # Build the final AuditReport
    report = AuditReport(
        repo_url=repo_url,
        executive_summary=executive_summary,
        overall_score=overall_score,
        criteria=criteria_results,
        remediation_plan=remediation_plan,
    )

    logger.info(
        "Chief Justice verdict: overall_score=%.1f across %d criteria",
        overall_score,
        len(criteria_results),
    )

    return {"final_report": report}
